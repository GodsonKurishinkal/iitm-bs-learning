{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from pandas import DataFrame, Series\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddedacb",
   "metadata": {},
   "source": [
    "## 1. Kernel of Linear Transformations\n",
    "### 1.1 Theory\n",
    "The kernel is the set of all inputs that map to the zero vector. It measures what information is \"lost\" by the transformation.\n",
    "\n",
    "### 1.2 Mathematical Definition\n",
    "$$\\ker(T) = \\{\\mathbf{v} \\in V : T(\\mathbf{v}) = \\mathbf{0}\\}$$\n",
    "\n",
    "**Properties**:\n",
    "- $\\ker(T)$ is a subspace of the domain\n",
    "- $T$ is injective (one-to-one) iff $\\ker(T) = \\{\\mathbf{0}\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Kernel - Implementation\n",
    "# TODO: Add kernel computation and analysis\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abd661",
   "metadata": {},
   "source": [
    "### 1.3 Supply Chain Application\n",
    "**Retail Context**: In dimensionality reduction (like PCA), the kernel represents information lost. Understanding the kernel helps assess what features become indistinguishable after transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e72af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply Chain Example: Information Loss Analysis\n",
    "# TODO: Add example analyzing dimensionality reduction\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b45c003",
   "metadata": {},
   "source": [
    "## 2. Image (Range) of Linear Transformations\n",
    "### 2.1 Theory\n",
    "The image is the set of all possible outputs of the transformation. It's a subspace of the codomain.\n",
    "\n",
    "### 2.2 Mathematical Definition\n",
    "$$\\text{im}(T) = \\{T(\\mathbf{v}) : \\mathbf{v} \\in V\\}$$\n",
    "\n",
    "**Properties**:\n",
    "- $\\text{im}(T)$ is a subspace of the codomain\n",
    "- $T$ is surjective (onto) iff $\\text{im}(T) = W$ (codomain)\n",
    "- $\\dim(\\ker(T)) + \\dim(\\text{im}(T)) = \\dim(V)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57894f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Image - Implementation\n",
    "# TODO: Add image/range computation\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572bbbfd",
   "metadata": {},
   "source": [
    "### 2.3 Supply Chain Application\n",
    "**Retail Context**: The image represents all reachable states. In production planning, it shows what outputs are achievable given the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply Chain Example: Reachable Outputs\n",
    "# TODO: Add example of achievable production states\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40f643",
   "metadata": {},
   "source": [
    "## 3. Injective, Surjective, Bijective\n",
    "### 3.1 Theory\n",
    "These properties describe whether a transformation preserves information and covers the target space.\n",
    "\n",
    "### 3.2 Mathematical Definition\n",
    "- **Injective** (1-to-1): $T(\\mathbf{u}) = T(\\mathbf{v}) \\Rightarrow \\mathbf{u} = \\mathbf{v}$\n",
    "- **Surjective** (onto): Every output is achieved\n",
    "- **Bijective**: Both injective and surjective; invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Properties Testing - Implementation\n",
    "# TODO: Add tests for injectivity and surjectivity\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f6bed",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "1. **Exercise 1**: Find the kernel and image of the projection matrix onto the xy-plane.\n",
    "2. **Exercise 2**: Determine if a feature transformation is injective (no information loss).\n",
    "3. **Exercise 3**: For a 3Ã—2 matrix, explain why it cannot be bijective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94865dac",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Kernel: inputs that map to zero; measures information loss\n",
    "- Image: all possible outputs; measures coverage\n",
    "- Injective: no information loss (trivial kernel)\n",
    "- Surjective: full coverage; Bijective: invertible\n",
    "\n",
    "## Next Week Preview\n",
    "Week 7 covers **Equivalent/Similar Matrices and Inner Products**.\n",
    "\n",
    "---\n",
    "*IIT Madras BS Degree in Data Science*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
