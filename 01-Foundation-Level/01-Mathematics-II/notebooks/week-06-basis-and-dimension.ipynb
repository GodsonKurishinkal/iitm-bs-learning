{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 6: Basis and Dimension\n\n**Course:** Mathematics for Data Science II (BSMA1003)  \n**Week:** 6\n\n## Learning Objectives\n- Master basis and dimension concepts\n- Apply to data science problems\n- Implement using NumPy and SciPy\n- Understand real-world applications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import linalg\n\nnp.random.seed(42)\nplt.style.use('seaborn-v0_8-whitegrid')\n%matplotlib inline\n\nprint('\u2713 Libraries loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Basis Definition\n\nA **basis** for vector space $V$ is a set of vectors that:\n1. **Span** $V$ (every vector in $V$ is a linear combination)\n2. Are **linearly independent**\n\n### Standard Basis for $\\mathbb{R}^3$\n$$e_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad e_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\quad e_3 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$$\n\nEvery vector $v = [x, y, z]^T = xe_1 + ye_2 + ze_3$\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Standard basis\ne1 = np.array([1, 0, 0])\ne2 = np.array([0, 1, 0])\ne3 = np.array([0, 0, 1])\n\nv = np.array([3, -2, 5])\nprint('Standard basis for R\u00b3:')\nprint(f'e1 = {e1}')\nprint(f'e2 = {e2}')\nprint(f'e3 = {e3}')\nprint(f'\\nAny vector v = {v}')\nprint(f'v = {v[0]}e1 + {v[1]}e2 + {v[2]}e3')\nprint(f'  = {v[0]*e1 + v[1]*e2 + v[2]*e3}')\nprint('\\n\u2713 Unique representation!')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Dimension\n\nThe **dimension** of vector space $V$:\n$$\\dim(V) = \\text{number of vectors in any basis}$$\n\nAll bases have the same size!\n\n### Examples\n- $\\dim(\\mathbb{R}^n) = n$\n- $\\dim(\\mathbb{R}^{m \\times n}) = mn$ (matrices)\n- $\\dim(P_n) = n+1$ (polynomials of degree $\\leq n$)\n- $\\dim(\\{0\\}) = 0$ (zero space)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Find basis for column space\nA = np.array([[1, 2, 3], [2, 4, 6], [1, 1, 2]])\nprint('Matrix A:')\nprint(A)\n\n# Use QR decomposition to find basis\nQ, R = np.linalg.qr(A)\nrank = np.linalg.matrix_rank(A)\n\nprint(f'\\nRank = {rank}')\nprint(f'Dimension of Col(A) = {rank}')\nprint('\\nBasis for Col(A):')\nfor i in range(rank):\n    print(f'v{i+1} = {Q[:, i]}')\n\nprint(f'\\n\u2713 {rank} independent vectors span the column space')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Coordinate Systems\n\nGiven basis $\\mathcal{B} = \\{b_1, ..., b_n\\}$, every $v \\in V$ has **unique** representation:\n$$v = c_1b_1 + ... + c_nb_n$$\n\n**Coordinate vector:** $[v]_\\mathcal{B} = \\begin{bmatrix} c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix}$\n\n### Change of Basis\nConvert between coordinate systems using change-of-basis matrix!\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Different bases for R\u00b2\nstandard_basis = np.array([[1, 0], [0, 1]]).T\nalternate_basis = np.array([[1, 1], [1, -1]]).T\n\nv = np.array([3, 1])\n\nprint('Vector v in standard coordinates:')\nprint(v)\n\n# Convert to alternate basis\nP = alternate_basis  # Change-of-basis matrix\nv_alt = np.linalg.solve(P, v)\nprint('\\nVector v in alternate basis coordinates:')\nprint(v_alt)\n\n# Verify\nv_reconstructed = P @ v_alt\nprint(f'\\nReconstruct: P\u00b7v_alt = {v_reconstructed}')\nprint(f'\u2713 Match: {np.allclose(v, v_reconstructed)}')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Fundamental Theorem\n\n### Rank-Nullity Theorem\nFor $A$ ($m \\times n$ matrix):\n$$\\text{rank}(A) + \\text{nullity}(A) = n$$\n\nwhere:\n- $\\text{rank}(A) = \\dim(\\text{Col}(A))$\n- $\\text{nullity}(A) = \\dim(\\text{Nul}(A))$\n\n### Implications\n- Total dimensions preserved\n- More independent columns \u2192 smaller null space\n- Relates four fundamental subspaces\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Verify rank-nullity theorem\nA = np.array([[1, 2, 3, 4], [2, 4, 6, 8], [1, 1, 2, 3]])\nprint('Matrix A (3\u00d74):')\nprint(A)\n\nm, n = A.shape\nrank = np.linalg.matrix_rank(A)\n\n# Null space dimension\n_, _, V = np.linalg.svd(A)\nnullity = n - rank\n\nprint(f'\\nn (columns) = {n}')\nprint(f'rank(A) = {rank}')\nprint(f'nullity(A) = {nullity}')\nprint(f'\\n\u2713 rank + nullity = {rank} + {nullity} = {rank + nullity} = {n}')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Finding Bases\n\n### Algorithm\n1. **Row reduce** to RREF\n2. **Pivot columns** form basis for column space\n3. **Free variables** correspond to null space basis\n\n### Orthonormal Basis\n**Gram-Schmidt** process creates orthonormal basis:\n- All vectors have unit length\n- All vectors perpendicular to each other\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Gram-Schmidt orthonormalization\nvectors = np.array([[1, 1, 0], [1, 0, 1], [0, 1, 1]], dtype=float).T\n\nprint('Original vectors (columns):')\nprint(vectors)\n\n# QR decomposition performs Gram-Schmidt\nQ, R = np.linalg.qr(vectors)\n\nprint('\\nOrthonormal basis (columns):')\nprint(Q)\n\n# Verify orthonormality\nprint('\\nVerification:')\nprint(f'||q1|| = {np.linalg.norm(Q[:, 0]):.6f}')\nprint(f'||q2|| = {np.linalg.norm(Q[:, 1]):.6f}')\nprint(f'||q3|| = {np.linalg.norm(Q[:, 2]):.6f}')\nprint(f'q1\u00b7q2 = {Q[:, 0] @ Q[:, 1]:.6f}')\nprint(f'q1\u00b7q3 = {Q[:, 0] @ Q[:, 2]:.6f}')\nprint(f'q2\u00b7q3 = {Q[:, 1] @ Q[:, 2]:.6f}')\nprint('\u2713 Orthonormal!')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Application: PCA Preview\n\n**Principal Component Analysis** finds optimal basis:\n- Maximizes variance\n- Components are orthogonal\n- Ordered by importance\n\nBasis = eigenvectors of covariance matrix!\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Simple PCA demonstration\nnp.random.seed(42)\nn_samples = 200\n\n# Generate correlated data\nX = np.random.randn(n_samples, 2)\nX[:, 1] = X[:, 0] + 0.5*np.random.randn(n_samples)\n\n# PCA: find principal components\ncov_matrix = np.cov(X.T)\neigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n\n# Sort by eigenvalue\nidx = eigenvalues.argsort()[::-1]\neigenvalues = eigenvalues[idx]\neigenvectors = eigenvectors[:, idx]\n\nplt.figure(figsize=(10, 8))\nplt.scatter(X[:, 0], X[:, 1], alpha=0.5, s=30)\n\n# Plot principal components\nscale = 2*np.sqrt(eigenvalues)\nfor i in range(2):\n    plt.arrow(0, 0, scale[i]*eigenvectors[0, i], scale[i]*eigenvectors[1, i],\n              head_width=0.3, head_length=0.2, fc=f'C{i+1}', ec=f'C{i+1}',\n              linewidth=3, label=f'PC{i+1} (\u03bb={eigenvalues[i]:.2f})')\n\nplt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\nplt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\nplt.xlabel('Feature 1', fontsize=12)\nplt.ylabel('Feature 2', fontsize=12)\nplt.title('Principal Components = New Basis', fontsize=14, fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n\nprint('Principal components form optimal basis for data!')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Summary\n\n### Key Concepts\n1. **Basis:** Minimal spanning set (independent + spanning)\n2. **Dimension:** Size of any basis\n3. **Coordinates:** Unique representation in given basis\n4. **Rank-Nullity:** $\\text{rank} + \\text{nullity} = n$\n\n### Finding Bases\n- Row reduction \u2192 pivot columns\n- QR decomposition \u2192 orthonormal basis\n- SVD \u2192 optimal bases\n\n### Applications\n- PCA: Optimal basis for data\n- Signal processing: Fourier basis\n- Compression: Sparse representations\n\n**Next:** Week 7 - Rank and Nullity in depth\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}