{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Expectations and Variance\n\n",
    "**Course:** Statistics for Data Science II (BSMA1004)  \n",
    "**Week:** 3 of 12\n\n",
    "## Learning Objectives\n",
    "- Master expectation and variance for functions of random variables\n",
    "- Apply Law of Total Expectation and Total Variance\n",
    "- Compute variance of sums of random variables\n",
    "- Use moment generating functions\n",
    "- Apply to real data science problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import factorial\n\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n\n",
    "print('\u2713 Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Expected Value of Functions\n\n",
    "### Definition\n",
    "For function g(X):\n\n",
    "**Discrete:** $E[g(X)] = \\sum_x g(x) p_X(x)$\n\n",
    "**Continuous:** $E[g(X)] = \\int_{-\\infty}^{\\infty} g(x) f_X(x) dx$\n\n",
    "### Properties\n",
    "1. $E[aX + b] = aE[X] + b$ (linearity)\n",
    "2. $E[X + Y] = E[X] + E[Y]$ (always true!)\n",
    "3. If X, Y independent: $E[XY] = E[X]E[Y]$\n",
    "4. $E[X^2] \\geq E[X]^2$ (Jensen's inequality for convex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Expected value of X\u00b2\n",
    "# Let X ~ Binomial(n=10, p=0.5)\n",
    "n, p = 10, 0.5\n",
    "X_vals = np.arange(0, n+1)\n",
    "pmf = stats.binom.pmf(X_vals, n, p)\n\n",
    "# E[X]\n",
    "E_X = np.sum(X_vals * pmf)\n",
    "print(f\"E[X] = {E_X:.3f}\")\n",
    "print(f\"Theoretical: n*p = {n*p}\")\n\n",
    "# E[X\u00b2]\n",
    "E_X2 = np.sum(X_vals**2 * pmf)\n",
    "print(f\"\\nE[X\u00b2] = {E_X2:.3f}\")\n\n",
    "# Verify Jensen: E[X\u00b2] \u2265 (E[X])\u00b2\n",
    "print(f\"E[X\u00b2] = {E_X2:.3f} \u2265 (E[X])\u00b2 = {E_X**2:.3f} \u2713\")\n\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n",
    "axes[0].bar(X_vals, pmf, alpha=0.7, color='steelblue')\n",
    "axes[0].axvline(E_X, color='red', linestyle='--', label=f'E[X]={E_X:.1f}')\n",
    "axes[0].set_xlabel('X', fontsize=12)\n",
    "axes[0].set_ylabel('P(X)', fontsize=12)\n",
    "axes[0].set_title('Distribution of X', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n\n",
    "axes[1].bar(X_vals, X_vals**2 * pmf, alpha=0.7, color='green')\n",
    "axes[1].axvline(E_X, color='red', linestyle='--', label=f'E[X]={E_X:.1f}')\n",
    "axes[1].set_xlabel('X', fontsize=12)\n",
    "axes[1].set_ylabel('X\u00b2 \u00d7 P(X)', fontsize=12)\n",
    "axes[1].set_title('E[X\u00b2] Calculation', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variance Properties\n\n",
    "### Definition\n",
    "$$\\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$\n\n",
    "### Key Properties\n",
    "1. $\\text{Var}(aX + b) = a^2 \\text{Var}(X)$ (constant doesn't affect variance)\n",
    "2. $\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)$\n",
    "3. If X, Y independent: $\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)$\n",
    "4. $\\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) - 2\\text{Cov}(X,Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Variance of sum\n",
    "# Independent case\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n\n",
    "X = np.random.normal(5, 2, n_samples)  # mean=5, std=2\n",
    "Y = np.random.normal(3, 1.5, n_samples)  # mean=3, std=1.5\n\n",
    "# X + Y\n",
    "Z = X + Y\n\n",
    "print(\"Independent Variables:\")\n",
    "print(f\"Var(X) = {np.var(X, ddof=1):.3f}\")\n",
    "print(f\"Var(Y) = {np.var(Y, ddof=1):.3f}\")\n",
    "print(f\"Var(X+Y) = {np.var(Z, ddof=1):.3f}\")\n",
    "print(f\"Var(X) + Var(Y) = {np.var(X, ddof=1) + np.var(Y, ddof=1):.3f} \u2713\")\n\n",
    "# Dependent case\n",
    "Y_dep = 0.8 * X + np.random.normal(0, 0.5, n_samples)  # Correlated\n",
    "Z_dep = X + Y_dep\n",
    "cov_xy = np.cov(X, Y_dep)[0, 1]\n\n",
    "print(\"\\nDependent Variables:\")\n",
    "print(f\"Var(X) = {np.var(X, ddof=1):.3f}\")\n",
    "print(f\"Var(Y) = {np.var(Y_dep, ddof=1):.3f}\")\n",
    "print(f\"Cov(X,Y) = {cov_xy:.3f}\")\n",
    "print(f\"Var(X+Y) = {np.var(Z_dep, ddof=1):.3f}\")\n",
    "print(f\"Var(X) + Var(Y) + 2Cov(X,Y) = {np.var(X, ddof=1) + np.var(Y_dep, ddof=1) + 2*cov_xy:.3f} \u2713\")\n\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n",
    "axes[0].hist(Z, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(Z.mean(), color='red', linestyle='--', label=f'Mean={Z.mean():.1f}')\n",
    "axes[0].set_xlabel('X + Y (Independent)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title(f'Var = {np.var(Z, ddof=1):.2f}', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n\n",
    "axes[1].hist(Z_dep, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].axvline(Z_dep.mean(), color='red', linestyle='--', label=f'Mean={Z_dep.mean():.1f}')\n",
    "axes[1].set_xlabel('X + Y (Dependent)', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title(f'Var = {np.var(Z_dep, ddof=1):.2f}', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Law of Total Expectation\n\n",
    "### Theorem\n",
    "$$E[X] = E[E[X|Y]]$$\n\n",
    "Also called **Tower Property** or **Iterated Expectation**\n\n",
    "### Intuition\n",
    "1. First compute E[X|Y=y] for each y\n",
    "2. Then average over all values of Y\n",
    "3. Result equals E[X]\n\n",
    "### Application\n",
    "Break complex expectation into simpler conditional expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Student test scores\n",
    "# Y = study hours (1, 2, or 3)\n",
    "# X = test score | Y ~ N(60 + 10*Y, 5\u00b2)\n\n",
    "study_hours = np.array([1, 2, 3])\n",
    "prob_study = np.array([0.3, 0.5, 0.2])  # P(Y)\n\n",
    "# E[X | Y=y] = 60 + 10*y\n",
    "conditional_means = 60 + 10 * study_hours\n\n",
    "# E[X] = E[E[X|Y]] = \u03a3 E[X|Y=y] P(Y=y)\n",
    "E_X = np.sum(conditional_means * prob_study)\n\n",
    "print(\"Law of Total Expectation\")\n",
    "print(\"=\"*50)\n",
    "for y, cond_mean, p in zip(study_hours, conditional_means, prob_study):\n",
    "    print(f\"E[Score | Study={y}hr] = {cond_mean}, P(Study={y}) = {p}\")\n\n",
    "print(f\"\\nE[Score] = {E_X:.1f}\")\n\n",
    "# Verify by simulation\n",
    "np.random.seed(42)\n",
    "n_students = 100000\n",
    "study_sim = np.random.choice(study_hours, size=n_students, p=prob_study)\n",
    "scores_sim = 60 + 10*study_sim + np.random.normal(0, 5, n_students)\n\n",
    "print(f\"Simulation: E[Score] \u2248 {scores_sim.mean():.1f} \u2713\")\n\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n\n",
    "for y in study_hours:\n",
    "    mask = study_sim == y\n",
    "    plt.hist(scores_sim[mask], bins=50, alpha=0.5, \n",
    "             label=f'{y} hr (E={scores_sim[mask].mean():.1f})')\n\n",
    "plt.axvline(E_X, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Overall E[Score]={E_X:.1f}')\n",
    "plt.xlabel('Test Score', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Law of Total Expectation: Test Scores', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Law of Total Variance\n\n",
    "### Theorem\n",
    "$$\\text{Var}(X) = E[\\text{Var}(X|Y)] + \\text{Var}(E[X|Y])$$\n\n",
    "### Interpretation\n",
    "- $E[\\text{Var}(X|Y)]$: **Within-group** variance (randomness within each Y)\n",
    "- $\\text{Var}(E[X|Y])$: **Between-group** variance (differences across Y values)\n",
    "- Total variance = Within + Between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue student example\n",
    "# Var(X|Y=y) = 5\u00b2 = 25 for all y\n",
    "within_var = 25\n\n",
    "# E[Var(X|Y)] = 25 (constant)\n",
    "E_within_var = within_var\n\n",
    "# Var(E[X|Y]) = Var(60 + 10Y) = 100\u00b7Var(Y)\n",
    "E_Y = np.sum(study_hours * prob_study)\n",
    "Var_Y = np.sum((study_hours - E_Y)**2 * prob_study)\n",
    "Var_between = 100 * Var_Y\n\n",
    "# Total variance\n",
    "Var_X_theory = E_within_var + Var_between\n",
    "Var_X_sim = np.var(scores_sim, ddof=1)\n\n",
    "print(\"Law of Total Variance\")\n",
    "print(\"=\"*50)\n",
    "print(f\"E[Var(X|Y)] (within) = {E_within_var:.2f}\")\n",
    "print(f\"Var(E[X|Y]) (between) = {Var_between:.2f}\")\n",
    "print(f\"\\nVar(X) theory = {Var_X_theory:.2f}\")\n",
    "print(f\"Var(X) simulation = {Var_X_sim:.2f} \u2713\")\n\n",
    "# Decomposition visualization\n",
    "labels = ['Within-Group\\nVariance', 'Between-Group\\nVariance']\n",
    "values = [E_within_var, Var_between]\n",
    "colors = ['lightblue', 'coral']\n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n",
    "axes[0].bar(labels, values, color=colors, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_ylabel('Variance', fontsize=12)\n",
    "axes[0].set_title('Variance Decomposition', fontsize=14, fontweight='bold')\n",
    "axes[0].axhline(Var_X_theory, color='red', linestyle='--', \n",
    "                label=f'Total={Var_X_theory:.1f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n\n",
    "# Box plot by study hours\n",
    "data_by_group = [scores_sim[study_sim == y] for y in study_hours]\n",
    "bp = axes[1].boxplot(data_by_group, labels=[f'{y} hr' for y in study_hours],\n",
    "                     patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightgreen')\n",
    "axes[1].set_xlabel('Study Hours', fontsize=12)\n",
    "axes[1].set_ylabel('Test Score', fontsize=12)\n",
    "axes[1].set_title('Within vs Between Group Variation', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Moment Generating Functions (MGF)\n\n",
    "### Definition\n",
    "$$M_X(t) = E[e^{tX}]$$\n\n",
    "### Why Useful?\n",
    "1. **Moments**: $E[X^n] = M_X^{(n)}(0)$ (nth derivative at 0)\n",
    "2. **Uniqueness**: MGF uniquely determines distribution\n",
    "3. **Sums**: If independent, $M_{X+Y}(t) = M_X(t) \\cdot M_Y(t)$\n\n",
    "### Common MGFs\n",
    "- **Bernoulli(p)**: $M(t) = 1-p + pe^t$\n",
    "- **Binomial(n,p)**: $M(t) = (1-p + pe^t)^n$\n",
    "- **Poisson(\u03bb)**: $M(t) = e^{\\lambda(e^t - 1)}$\n",
    "- **Normal(\u03bc,\u03c3\u00b2)**: $M(t) = e^{\\mu t + \\frac{1}{2}\\sigma^2 t^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sum of independent Poissons\n",
    "# X ~ Poisson(\u03bb\u2081), Y ~ Poisson(\u03bb\u2082), independent\n",
    "# Prove: X + Y ~ Poisson(\u03bb\u2081 + \u03bb\u2082) using MGF\n\n",
    "lambda1 = 3\n",
    "lambda2 = 5\n",
    "n_samples = 10000\n\n",
    "# Simulate\n",
    "np.random.seed(42)\n",
    "X = np.random.poisson(lambda1, n_samples)\n",
    "Y = np.random.poisson(lambda2, n_samples)\n",
    "Z = X + Y\n\n",
    "# Theory: Z ~ Poisson(\u03bb\u2081 + \u03bb\u2082)\n",
    "Z_theory = np.random.poisson(lambda1 + lambda2, n_samples)\n\n",
    "print(\"Sum of Independent Poissons\")\n",
    "print(\"=\"*50)\n",
    "print(f\"X ~ Poisson({lambda1})\")\n",
    "print(f\"Y ~ Poisson({lambda2})\")\n",
    "print(f\"\\nTheory: X+Y ~ Poisson({lambda1 + lambda2})\")\n",
    "print(f\"\\nSimulation:\")\n",
    "print(f\"  E[X+Y] = {Z.mean():.3f} (theory: {lambda1 + lambda2})\")\n",
    "print(f\"  Var[X+Y] = {Z.var():.3f} (theory: {lambda1 + lambda2})\")\n\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n",
    "axes[0, 0].hist(X, bins=range(0, 15), alpha=0.7, color='blue', edgecolor='black', density=True)\n",
    "axes[0, 0].set_title(f'X ~ Poisson({lambda1})', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('X')\n",
    "axes[0, 0].set_ylabel('Probability')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n\n",
    "axes[0, 1].hist(Y, bins=range(0, 15), alpha=0.7, color='green', edgecolor='black', density=True)\n",
    "axes[0, 1].set_title(f'Y ~ Poisson({lambda2})', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Y')\n",
    "axes[0, 1].set_ylabel('Probability')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n\n",
    "axes[1, 0].hist(Z, bins=range(0, 20), alpha=0.7, color='orange', edgecolor='black', \n",
    "                density=True, label='Simulation')\n",
    "z_vals = np.arange(0, 20)\n",
    "axes[1, 0].plot(z_vals, stats.poisson.pmf(z_vals, lambda1 + lambda2), \n",
    "                'ro-', label='Theory', linewidth=2, markersize=8)\n",
    "axes[1, 0].set_title(f'X+Y (Simulation vs Theory)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('X + Y')\n",
    "axes[1, 0].set_ylabel('Probability')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n\n",
    "axes[1, 1].text(0.5, 0.5, \n",
    "                f\"MGF Proof:\\n\\n\"\n",
    "                f\"$M_X(t) = e^{{\\lambda_1(e^t-1)}}$\\n\\n\"\n",
    "                f\"$M_Y(t) = e^{{\\lambda_2(e^t-1)}}$\\n\\n\"\n",
    "                f\"$M_{{X+Y}}(t) = M_X(t)M_Y(t)$\\n\\n\"\n",
    "                f\"$= e^{{(\\lambda_1+\\lambda_2)(e^t-1)}}$\\n\\n\"\n",
    "                f\"$\\\\Rightarrow X+Y \\\\sim Poisson(\\lambda_1+\\lambda_2)$ \u2713\",\n",
    "                ha='center', va='center', fontsize=14,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "axes[1, 1].axis('off')\n\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Application: Portfolio Risk\n\n",
    "### Problem\n",
    "Investor has portfolio: 40% Stock A, 60% Stock B\n",
    "- Return_A ~ N(0.10, 0.20\u00b2)\n",
    "- Return_B ~ N(0.08, 0.15\u00b2)\n",
    "- Correlation \u03c1 = 0.6\n\n",
    "Find E[Return] and Var[Return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio parameters\n",
    "w_A, w_B = 0.4, 0.6\n",
    "mu_A, sigma_A = 0.10, 0.20\n",
    "mu_B, sigma_B = 0.08, 0.15\n",
    "rho = 0.6\n\n",
    "# Portfolio return: R = w_A*R_A + w_B*R_B\n",
    "E_R = w_A * mu_A + w_B * mu_B\n\n",
    "# Variance\n",
    "Var_R = (w_A**2 * sigma_A**2 + \n",
    "         w_B**2 * sigma_B**2 + \n",
    "         2*w_A*w_B*rho*sigma_A*sigma_B)\n",
    "sigma_R = np.sqrt(Var_R)\n\n",
    "print(\"Portfolio Analysis\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Weights: {w_A*100:.0f}% A, {w_B*100:.0f}% B\")\n",
    "print(f\"\\nExpected Return:\")\n",
    "print(f\"  E[R] = {E_R:.4f} ({E_R*100:.2f}%)\")\n",
    "print(f\"\\nRisk (Standard Deviation):\")\n",
    "print(f\"  \u03c3_R = {sigma_R:.4f} ({sigma_R*100:.2f}%)\")\n\n",
    "# Simulation\n",
    "np.random.seed(42)\n",
    "n_days = 10000\n",
    "mean = [mu_A, mu_B]\n",
    "cov = [[sigma_A**2, rho*sigma_A*sigma_B],\n",
    "       [rho*sigma_A*sigma_B, sigma_B**2]]\n",
    "returns = np.random.multivariate_normal(mean, cov, n_days)\n",
    "R_A, R_B = returns[:, 0], returns[:, 1]\n",
    "R_portfolio = w_A * R_A + w_B * R_B\n\n",
    "print(f\"\\nSimulation Verification:\")\n",
    "print(f\"  E[R] \u2248 {R_portfolio.mean():.4f} \u2713\")\n",
    "print(f\"  \u03c3_R \u2248 {R_portfolio.std():.4f} \u2713\")\n\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n",
    "# Histogram\n",
    "axes[0].hist(R_portfolio, bins=50, alpha=0.7, color='purple', edgecolor='black', density=True)\n",
    "x = np.linspace(R_portfolio.min(), R_portfolio.max(), 100)\n",
    "axes[0].plot(x, stats.norm.pdf(x, E_R, sigma_R), 'r-', linewidth=2, label='Theory')\n",
    "axes[0].axvline(E_R, color='green', linestyle='--', label=f'E[R]={E_R:.3f}')\n",
    "axes[0].set_xlabel('Portfolio Return', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title('Portfolio Return Distribution', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n\n",
    "# Risk-Return scatter\n",
    "axes[1].scatter([sigma_A], [mu_A], s=200, marker='o', color='blue', label='Stock A', alpha=0.7)\n",
    "axes[1].scatter([sigma_B], [mu_B], s=200, marker='s', color='green', label='Stock B', alpha=0.7)\n",
    "axes[1].scatter([sigma_R], [E_R], s=300, marker='*', color='purple', label='Portfolio', alpha=0.9)\n",
    "axes[1].set_xlabel('Risk (\u03c3)', fontsize=12)\n",
    "axes[1].set_ylabel('Expected Return (\u03bc)', fontsize=12)\n",
    "axes[1].set_title('Risk-Return Trade-off', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n\n",
    "plt.tight_layout()\n",
    "plt.show()\n\n",
    "print(f\"\\n\ud83d\udca1 Diversification benefit: Portfolio risk ({sigma_R:.3f}) < Weighted avg ({w_A*sigma_A + w_B*sigma_B:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practice Problems\n\n",
    "### Problem 1\n",
    "If X ~ Uniform(0, 1), find E[X\u00b2] and Var(X)\n\n",
    "### Problem 2  \n",
    "Use Law of Total Expectation: coin with P(H)=p. If H, roll die. Find E[Roll]\n\n",
    "### Problem 3\n",
    "If X, Y independent with Var(X)=4, Var(Y)=9, find Var(2X - 3Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SOLUTIONS\")\n",
    "print(\"=\"*60)\n\n",
    "# Problem 1\n",
    "print(\"\\n\ud83d\udcdd Problem 1: Uniform(0,1)\")\n",
    "print(\"E[X] = (0+1)/2 = 0.5\")\n",
    "print(\"E[X\u00b2] = \u222b\u2080\u00b9 x\u00b2 dx = x\u00b3/3 |\u2080\u00b9 = 1/3\")\n",
    "print(\"Var(X) = E[X\u00b2] - (E[X])\u00b2 = 1/3 - 1/4 = 1/12\")\n",
    "print(f\"Verification: 1/12 = {1/12:.4f}\")\n\n",
    "# Problem 2\n",
    "print(\"\\n\ud83d\udcdd Problem 2: Law of Total Expectation\")\n",
    "print(\"E[Roll] = E[E[Roll | Coin]]\")\n",
    "print(\"E[Roll | H] = 3.5 (average die roll)\")\n",
    "print(\"E[Roll | T] = 0 (don't roll)\")\n",
    "print(\"E[Roll] = p\u00b73.5 + (1-p)\u00b70 = 3.5p\")\n",
    "p = 0.6\n",
    "print(f\"\\nIf p={p}: E[Roll] = {3.5*p:.2f}\")\n\n",
    "# Problem 3\n",
    "print(\"\\n\ud83d\udcdd Problem 3: Variance of Linear Combination\")\n",
    "print(\"Var(2X - 3Y) = Var(2X) + Var(-3Y) (independent)\")\n",
    "print(\"             = 4\u00b7Var(X) + 9\u00b7Var(Y)\")\n",
    "var_x, var_y = 4, 9\n",
    "result = 4*var_x + 9*var_y\n",
    "print(f\"             = 4\u00b7{var_x} + 9\u00b7{var_y}\")\n",
    "print(f\"             = {result}\")\n\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary & Key Takeaways\n\n",
    "### \ud83d\udcda Core Concepts\n",
    "1. **E[g(X)]**: Expectation of functions uses $\\sum g(x)p(x)$ or $\\int g(x)f(x)dx$\n",
    "2. **Variance Properties**: $\\text{Var}(aX+b) = a^2\\text{Var}(X)$, $\\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)$\n",
    "3. **Law of Total Expectation**: $E[X] = E[E[X|Y]]$ - break into conditional expectations\n",
    "4. **Law of Total Variance**: $\\text{Var}(X) = E[\\text{Var}(X|Y)] + \\text{Var}(E[X|Y])$ - within + between\n",
    "5. **MGF**: $M_X(t) = E[e^{tX}]$ - uniquely determines distribution, useful for sums\n\n",
    "### \ud83d\udd11 Key Formulas\n",
    "- $\\text{Var}(X) = E[X^2] - (E[X])^2$\n",
    "- Independent: $E[XY] = E[X]E[Y]$, $\\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y)$\n",
    "- MGF sum: $M_{X+Y}(t) = M_X(t) \\cdot M_Y(t)$ if independent\n\n",
    "### \ud83c\udfaf Applications\n",
    "- **Portfolio Theory**: Expected return and risk\n",
    "- **Risk Analysis**: Variance decomposition\n",
    "- **Insurance**: Total expectation for claims\n",
    "- **Probability Proofs**: MGF for distribution identification\n\n",
    "### \ud83d\ude80 Next Week\n",
    "**Week 4: Advanced Continuous Distributions**\n",
    "- Exponential & Gamma distributions\n",
    "- Beta distribution\n",
    "- Joint continuous distributions\n",
    "- Transformations of variables\n\n",
    "---\n",
    "**\ud83c\udf93 End of Week 3**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}