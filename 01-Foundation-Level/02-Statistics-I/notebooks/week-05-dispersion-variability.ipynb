{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 5: Measures of Dispersion and Variability",
        "",
        "---",
        "**Date**: 2025-11-22",
        "**Course**: BSMA1002 - Statistics for Data Science I",
        "**Week**: 5 of 12",
        "**Topic**: Descriptive Statistics - Variability",
        "---",
        "",
        "## Learning Objectives",
        "",
        "- Understand why measuring spread is as important as measuring center",
        "- Calculate and interpret range, variance, and standard deviation",
        "- Use IQR and detect outliers",
        "- Compare datasets using coefficient of variation",
        "- Visualize variability with box plots and error bars",
        "- Apply dispersion measures to real-world data analysis",
        "",
        "## Prerequisites",
        "",
        "```python",
        "import numpy as np",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from scipy import stats",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np",
        "import pandas as pd",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from scipy import stats",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "np.random.seed(42)",
        "plt.style.use('seaborn-v0_8-darkgrid')",
        "sns.set_palette(\"husl\")",
        "",
        "print(\"\u2713 Libraries imported successfully\")",
        "print(f\"NumPy: {np.__version__}, Pandas: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Why Measure Variability?",
        "",
        "**Central tendency tells us WHERE the data centers, but VARIABILITY tells us HOW SPREAD OUT it is.**",
        "",
        "### Two Datasets with Same Mean",
        "",
        "Consider these temperature readings from two cities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Two cities with same mean but different variability",
        "city_a = np.array([20, 21, 20, 19, 20, 21, 20, 19])  # Consistent",
        "city_b = np.array([5, 10, 25, 30, 15, 22, 18, 35])   # Variable",
        "",
        "mean_a, mean_b = np.mean(city_a), np.mean(city_b)",
        "",
        "print(\"Temperature Data (\u00b0C):\")",
        "print(\"=\" * 60)",
        "print(f\"City A: {city_a}\")",
        "print(f\"  Mean: {mean_a:.1f}\u00b0C\")",
        "print(f\"\\nCity B: {city_b}\")",
        "print(f\"  Mean: {mean_b:.1f}\u00b0C\")",
        "",
        "# Visualize",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))",
        "",
        "ax1.plot(city_a, 'o-', linewidth=2, markersize=8, label='City A')",
        "ax1.axhline(mean_a, color='r', linestyle='--', label=f'Mean = {mean_a:.1f}')",
        "ax1.fill_between(range(len(city_a)), city_a.min(), city_a.max(), alpha=0.2)",
        "ax1.set_title('City A: Low Variability', fontweight='bold')",
        "ax1.set_xlabel('Day')",
        "ax1.set_ylabel('Temperature (\u00b0C)')",
        "ax1.legend()",
        "ax1.grid(True, alpha=0.3)",
        "",
        "ax2.plot(city_b, 'o-', linewidth=2, markersize=8, label='City B', color='orange')",
        "ax2.axhline(mean_b, color='r', linestyle='--', label=f'Mean = {mean_b:.1f}')",
        "ax2.fill_between(range(len(city_b)), city_b.min(), city_b.max(), alpha=0.2)",
        "ax2.set_title('City B: High Variability', fontweight='bold')",
        "ax2.set_xlabel('Day')",
        "ax2.set_ylabel('Temperature (\u00b0C)')",
        "ax2.legend()",
        "ax2.grid(True, alpha=0.3)",
        "",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(\"\\n\ud83d\udd0d Same mean, VERY different spread!\")",
        "print(\"    We need measures of VARIABILITY to distinguish them!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Range",
        "",
        "**Definition**: Difference between maximum and minimum values",
        "",
        "$$\\text{Range} = \\text{Max} - \\text{Min}$$",
        "",
        "### Pros and Cons",
        "",
        "\u2705 Simple to calculate and interpret  ",
        "\u2705 Shows full spread of data  ",
        "\u274c Only uses two values (ignores all others)  ",
        "\u274c Extremely sensitive to outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate range for both cities",
        "range_a = city_a.max() - city_a.min()",
        "range_b = city_b.max() - city_b.min()",
        "",
        "print(\"Range Calculation:\")",
        "print(\"=\" * 60)",
        "print(f\"City A: {city_a.max()}\u00b0C - {city_a.min()}\u00b0C = {range_a}\u00b0C\")",
        "print(f\"City B: {city_b.max()}\u00b0C - {city_b.min()}\u00b0C = {range_b}\u00b0C\")",
        "",
        "# Demonstrate outlier sensitivity",
        "data_no_outlier = np.array([10, 12, 15, 13, 14, 11, 16, 12])",
        "data_with_outlier = np.append(data_no_outlier, 100)",
        "",
        "print(f\"\\nOutlier Sensitivity:\")",
        "print(f\"  Without outlier - Range: {data_no_outlier.ptp()}\")",
        "print(f\"  With outlier    - Range: {data_with_outlier.ptp()}\")",
        "print(f\"  Impact: Range increased {data_with_outlier.ptp() / data_no_outlier.ptp():.1f}x!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Variance",
        "",
        "**Definition**: Average of squared deviations from the mean",
        "",
        "**Population variance:**",
        "$$\\sigma^2 = \\frac{\\sum_{i=1}^{n}(x_i - \\mu)^2}{n}$$",
        "",
        "**Sample variance** (unbiased):",
        "$$s^2 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}$$",
        "",
        "### Why Square the Deviations?",
        "",
        "1. Negative and positive deviations don't cancel out",
        "2. Larger deviations get more weight",
        "3. Mathematical properties useful for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate variance step by step",
        "data = np.array([4, 8, 6, 5, 3, 7])",
        "",
        "print(\"Variance Calculation (Step by Step)\")",
        "print(\"=\" * 60)",
        "print(f\"Data: {data}\")",
        "",
        "# Step 1: Mean",
        "mean = data.mean()",
        "print(f\"\\n1. Calculate mean: {mean:.2f}\")",
        "",
        "# Step 2: Deviations",
        "deviations = data - mean",
        "print(f\"\\n2. Deviations from mean:\")",
        "for i, (x, dev) in enumerate(zip(data, deviations)):",
        "    print(f\"   {x} - {mean:.2f} = {dev:+.2f}\")",
        "",
        "# Step 3: Squared deviations",
        "squared_devs = deviations ** 2",
        "print(f\"\\n3. Squared deviations:\")",
        "for dev, sq_dev in zip(deviations, squared_devs):",
        "    print(f\"   ({dev:+.2f})\u00b2 = {sq_dev:.2f}\")",
        "",
        "# Step 4: Average",
        "print(f\"\\n4. Sum of squared deviations: {squared_devs.sum():.2f}\")",
        "print(f\"   n - 1 = {len(data) - 1}\")",
        "variance = squared_devs.sum() / (len(data) - 1)",
        "print(f\"   Variance (s\u00b2) = {squared_devs.sum():.2f} / {len(data) - 1} = {variance:.2f}\")",
        "",
        "# Verify with NumPy",
        "np_variance = np.var(data, ddof=1)  # ddof=1 for sample variance",
        "print(f\"\\n\u2713 NumPy variance: {np_variance:.2f}\")",
        "",
        "# Visualize deviations",
        "fig, ax = plt.subplots(figsize=(12, 6))",
        "x_pos = np.arange(len(data))",
        "bars = ax.bar(x_pos, data, alpha=0.6, edgecolor='black')",
        "ax.axhline(mean, color='r', linestyle='--', linewidth=2, label=f'Mean = {mean:.2f}')",
        "",
        "# Draw deviation lines",
        "for i, (val, dev) in enumerate(zip(data, deviations)):",
        "    ax.plot([i, i], [mean, val], 'g-', linewidth=2, alpha=0.7)",
        "    ax.text(i, val + 0.3, f'{dev:+.2f}', ha='center', fontsize=9)",
        "",
        "ax.set_xlabel('Data Point Index', fontsize=12)",
        "ax.set_ylabel('Value', fontsize=12)",
        "ax.set_title('Deviations from Mean (Variance Calculation)', fontsize=14, fontweight='bold')",
        "ax.set_xticks(x_pos)",
        "ax.legend()",
        "ax.grid(True, alpha=0.3, axis='y')",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Standard Deviation",
        "",
        "**Definition**: Square root of variance",
        "",
        "$$\\sigma = \\sqrt{\\sigma^2} \\quad \\text{or} \\quad s = \\sqrt{s^2}$$",
        "",
        "### Why Use Standard Deviation?",
        "",
        "\u2705 Same units as original data (variance is squared units)  ",
        "\u2705 More interpretable  ",
        "\u2705 Used in 68-95-99.7 rule for normal distributions  ",
        "\u2705 Standard measure for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare variance and standard deviation",
        "data_examples = {",
        "    'Test Scores': np.array([75, 82, 88, 79, 91, 85, 77]),",
        "    'Salaries ($1000s)': np.array([45, 52, 48, 55, 50, 47, 53]),",
        "    'Heights (cm)': np.array([165, 172, 168, 170, 175, 169, 171])",
        "}",
        "",
        "print(\"Variance vs Standard Deviation\")",
        "print(\"=\" * 70)",
        "",
        "for name, data in data_examples.items():",
        "    mean = data.mean()",
        "    variance = data.var(ddof=1)",
        "    std_dev = data.std(ddof=1)",
        "    ",
        "    print(f\"\\n{name}:\")",
        "    print(f\"  Mean:     {mean:.2f}\")",
        "    print(f\"  Variance: {variance:.2f} (squared units)\")",
        "    print(f\"  Std Dev:  {std_dev:.2f} (same units as data)\")",
        "    print(f\"  Range:    [{mean - std_dev:.2f}, {mean + std_dev:.2f}]\")",
        "",
        "# Visualize for test scores",
        "scores = data_examples['Test Scores']",
        "mean_scores = scores.mean()",
        "std_scores = scores.std(ddof=1)",
        "",
        "fig, ax = plt.subplots(figsize=(12, 6))",
        "ax.scatter(range(len(scores)), scores, s=100, zorder=3, label='Scores')",
        "ax.axhline(mean_scores, color='r', linestyle='-', linewidth=2, label=f'Mean = {mean_scores:.1f}')",
        "ax.axhline(mean_scores + std_scores, color='g', linestyle='--', linewidth=2, ",
        "           label=f'Mean \u00b1 1 SD')",
        "ax.axhline(mean_scores - std_scores, color='g', linestyle='--', linewidth=2)",
        "ax.fill_between(range(len(scores)), mean_scores - std_scores, mean_scores + std_scores,",
        "                alpha=0.2, color='green')",
        "",
        "ax.text(len(scores)-0.5, mean_scores + std_scores + 1, f'+1\u03c3 = {mean_scores + std_scores:.1f}',",
        "        fontsize=10)",
        "ax.text(len(scores)-0.5, mean_scores - std_scores - 1, f'-1\u03c3 = {mean_scores - std_scores:.1f}',",
        "        fontsize=10)",
        "",
        "ax.set_xlabel('Student Index', fontsize=12)",
        "ax.set_ylabel('Score', fontsize=12)",
        "ax.set_title('Standard Deviation: \u00b11\u03c3 Range', fontsize=14, fontweight='bold')",
        "ax.legend()",
        "ax.grid(True, alpha=0.3)",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Quartiles and Interquartile Range (IQR)",
        "",
        "**Quartiles** divide sorted data into four equal parts:",
        "- Q1 (25th percentile): 25% of data below",
        "- Q2 (50th percentile): Median",
        "- Q3 (75th percentile): 75% of data below",
        "",
        "**Interquartile Range (IQR)**:",
        "$$\\text{IQR} = Q3 - Q1$$",
        "",
        "### Advantages",
        "\u2705 Resistant to outliers  ",
        "\u2705 Focuses on middle 50% of data  ",
        "\u2705 Used in box plots  ",
        "\u2705 Outlier detection method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate quartiles and IQR",
        "data = np.array([12, 15, 18, 20, 22, 25, 28, 30, 35, 40, 45, 50, 100])  # Note outlier",
        "",
        "print(\"Quartiles and IQR Calculation\")",
        "print(\"=\" * 60)",
        "print(f\"Data: {data}\")",
        "print(f\"Sorted: {np.sort(data)}\")",
        "",
        "# Calculate quartiles",
        "Q1 = np.percentile(data, 25)",
        "Q2 = np.percentile(data, 50)  # median",
        "Q3 = np.percentile(data, 75)",
        "IQR = Q3 - Q1",
        "",
        "print(f\"\\nQuartiles:\")",
        "print(f\"  Q1 (25th percentile): {Q1:.2f}\")",
        "print(f\"  Q2 (50th percentile/Median): {Q2:.2f}\")",
        "print(f\"  Q3 (75th percentile): {Q3:.2f}\")",
        "print(f\"\\nIQR = Q3 - Q1 = {Q3:.2f} - {Q1:.2f} = {IQR:.2f}\")",
        "",
        "# Outlier detection using IQR method",
        "lower_fence = Q1 - 1.5 * IQR",
        "upper_fence = Q3 + 1.5 * IQR",
        "outliers = data[(data < lower_fence) | (data > upper_fence)]",
        "",
        "print(f\"\\nOutlier Detection (1.5 \u00d7 IQR rule):\")",
        "print(f\"  Lower fence: Q1 - 1.5\u00d7IQR = {Q1:.2f} - {1.5*IQR:.2f} = {lower_fence:.2f}\")",
        "print(f\"  Upper fence: Q3 + 1.5\u00d7IQR = {Q3:.2f} + {1.5*IQR:.2f} = {upper_fence:.2f}\")",
        "print(f\"  Outliers: {outliers}\")",
        "",
        "# Box plot visualization",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))",
        "",
        "# Detailed box plot",
        "bp = ax1.boxplot(data, vert=True, patch_artist=True, widths=0.5)",
        "bp['boxes'][0].set_facecolor('lightblue')",
        "bp['boxes'][0].set_edgecolor('black')",
        "bp['medians'][0].set_color('red')",
        "bp['medians'][0].set_linewidth(2)",
        "",
        "# Add labels",
        "ax1.text(1.15, Q1, f'Q1 = {Q1:.1f}', fontsize=10, va='center')",
        "ax1.text(1.15, Q2, f'Q2 = {Q2:.1f}', fontsize=10, va='center')",
        "ax1.text(1.15, Q3, f'Q3 = {Q3:.1f}', fontsize=10, va='center')",
        "ax1.text(1.15, lower_fence, f'Lower fence', fontsize=9, va='center', style='italic')",
        "ax1.text(1.15, upper_fence, f'Upper fence', fontsize=9, va='center', style='italic')",
        "",
        "ax1.set_ylabel('Value', fontsize=12)",
        "ax1.set_title('Box Plot with Outlier Detection', fontsize=13, fontweight='bold')",
        "ax1.set_xticks([])",
        "ax1.grid(True, alpha=0.3, axis='y')",
        "",
        "# Show IQR range",
        "ax2.hist(data, bins=15, edgecolor='black', alpha=0.7)",
        "ax2.axvline(Q1, color='g', linestyle='--', linewidth=2, label='Q1')",
        "ax2.axvline(Q3, color='r', linestyle='--', linewidth=2, label='Q3')",
        "ax2.axvspan(Q1, Q3, alpha=0.2, color='yellow', label=f'IQR = {IQR:.1f}')",
        "ax2.axvline(Q2, color='b', linestyle='-', linewidth=2, label='Median')",
        "",
        "for outlier in outliers:",
        "    ax2.axvline(outlier, color='red', linestyle=':', linewidth=1.5, alpha=0.7)",
        "    ax2.text(outlier, ax2.get_ylim()[1]*0.9, 'Outlier', rotation=90, ",
        "             fontsize=9, ha='right', color='red')",
        "",
        "ax2.set_xlabel('Value', fontsize=12)",
        "ax2.set_ylabel('Frequency', fontsize=12)",
        "ax2.set_title('Histogram with Quartiles and IQR', fontsize=13, fontweight='bold')",
        "ax2.legend()",
        "ax2.grid(True, alpha=0.3, axis='y')",
        "",
        "plt.tight_layout()",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Coefficient of Variation (CV)",
        "",
        "**Definition**: Standardized measure of dispersion",
        "",
        "$$CV = \\frac{s}{\\bar{x}} \\times 100\\%$$",
        "",
        "### When to Use CV",
        "",
        "\u2705 Comparing variability of datasets with different units  ",
        "\u2705 Comparing datasets with different scales  ",
        "\u2705 Assessing relative variability",
        "",
        "**Example**: Compare variability of heights (cm) vs weights (kg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare datasets using CV",
        "datasets = {",
        "    'Heights (cm)': np.array([165, 170, 175, 168, 172, 169, 171, 173]),",
        "    'Weights (kg)': np.array([60, 65, 70, 62, 68, 64, 66, 69]),",
        "    'Income ($1000s)': np.array([45, 50, 55, 48, 52, 49, 51, 53])",
        "}",
        "",
        "print(\"Coefficient of Variation Comparison\")",
        "print(\"=\" * 70)",
        "",
        "cv_results = []",
        "for name, data in datasets.items():",
        "    mean = data.mean()",
        "    std = data.std(ddof=1)",
        "    cv = (std / mean) * 100",
        "    cv_results.append((name, mean, std, cv))",
        "    ",
        "    print(f\"\\n{name}:\")",
        "    print(f\"  Mean: {mean:.2f}\")",
        "    print(f\"  Std Dev: {std:.2f}\")",
        "    print(f\"  CV: {cv:.2f}%\")",
        "",
        "# Visualize",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))",
        "",
        "# Standard deviations (not comparable due to different scales)",
        "names = [name.split()[0] for name in datasets.keys()]",
        "stds = [result[2] for result in cv_results]",
        "ax1.bar(names, stds, edgecolor='black', alpha=0.7)",
        "ax1.set_ylabel('Standard Deviation', fontsize=12)",
        "ax1.set_title('Standard Deviations\\n(NOT Comparable - Different Units)', ",
        "             fontsize=12, fontweight='bold')",
        "ax1.grid(True, alpha=0.3, axis='y')",
        "",
        "# CVs (comparable)",
        "cvs = [result[3] for result in cv_results]",
        "bars = ax2.bar(names, cvs, edgecolor='black', alpha=0.7, color='green')",
        "ax2.set_ylabel('Coefficient of Variation (%)', fontsize=12)",
        "ax2.set_title('Coefficients of Variation\\n(Comparable - Standardized)', ",
        "             fontsize=12, fontweight='bold')",
        "ax2.grid(True, alpha=0.3, axis='y')",
        "",
        "# Add value labels",
        "for bar, cv in zip(bars, cvs):",
        "    height = bar.get_height()",
        "    ax2.text(bar.get_x() + bar.get_width()/2, height + 0.1,",
        "            f'{cv:.1f}%', ha='center', fontsize=10, fontweight='bold')",
        "",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "print(f\"\\n\ud83d\udcca CV allows comparison across different scales!\")",
        "print(f\"    Highest relative variability: {cv_results[np.argmax(cvs)][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Real-World Application: Stock Portfolio Analysis",
        "",
        "Analyze risk (variability) vs return for different investment options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate monthly returns for different investments",
        "np.random.seed(42)",
        "",
        "# Different investment options",
        "investments = {",
        "    'Safe Bond': np.random.normal(2, 1, 36),      # Low return, low risk",
        "    'Blue Chip Stock': np.random.normal(5, 3, 36),  # Medium return, medium risk",
        "    'Tech Stock': np.random.normal(8, 8, 36),     # High return, high risk",
        "    'Crypto': np.random.normal(10, 15, 36)        # Very high return, very high risk",
        "}",
        "",
        "print(\"Investment Risk-Return Analysis (36 months)\")",
        "print(\"=\" * 70)",
        "",
        "results = []",
        "for name, returns in investments.items():",
        "    mean_return = returns.mean()",
        "    std_dev = returns.std(ddof=1)",
        "    cv = (std_dev / abs(mean_return)) * 100 if mean_return != 0 else 0",
        "    min_return = returns.min()",
        "    max_return = returns.max()",
        "    ",
        "    results.append({",
        "        'Investment': name,",
        "        'Mean Return (%)': mean_return,",
        "        'Std Dev (%)': std_dev,",
        "        'CV (%)': cv,",
        "        'Min (%)': min_return,",
        "        'Max (%)': max_return",
        "    })",
        "    ",
        "    print(f\"\\n{name}:\")",
        "    print(f\"  Average Monthly Return: {mean_return:.2f}%\")",
        "    print(f\"  Risk (Std Dev): {std_dev:.2f}%\")",
        "    print(f\"  Coefficient of Variation: {cv:.2f}%\")",
        "    print(f\"  Range: [{min_return:.2f}%, {max_return:.2f}%]\")",
        "",
        "# Create comprehensive visualization",
        "fig = plt.figure(figsize=(16, 10))",
        "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)",
        "",
        "# 1. Risk-Return Scatter",
        "ax1 = fig.add_subplot(gs[0, :])",
        "means = [r['Mean Return (%)'] for r in results]",
        "stds = [r['Std Dev (%)'] for r in results]",
        "names = [r['Investment'] for r in results]",
        "",
        "ax1.scatter(stds, means, s=300, alpha=0.6, c=range(len(results)), cmap='viridis')",
        "for i, name in enumerate(names):",
        "    ax1.annotate(name, (stds[i], means[i]), fontsize=11, fontweight='bold',",
        "                ha='center', va='center')",
        "",
        "ax1.set_xlabel('Risk (Standard Deviation %)', fontsize=12)",
        "ax1.set_ylabel('Return (Mean %)', fontsize=12)",
        "ax1.set_title('Risk vs Return Profile', fontsize=14, fontweight='bold')",
        "ax1.grid(True, alpha=0.3)",
        "",
        "# 2-5. Individual time series",
        "for idx, (name, returns) in enumerate(investments.items()):",
        "    row = (idx // 2) + 1",
        "    col = idx % 2",
        "    ax = fig.add_subplot(gs[row, col])",
        "    ",
        "    months = range(len(returns))",
        "    ax.plot(months, returns, 'o-', linewidth=1.5, markersize=4, alpha=0.7)",
        "    ax.axhline(returns.mean(), color='r', linestyle='--', linewidth=2,",
        "               label=f'Mean = {returns.mean():.1f}%')",
        "    ax.fill_between(months, ",
        "                    returns.mean() - returns.std(),",
        "                    returns.mean() + returns.std(),",
        "                    alpha=0.2, color='green', label='\u00b11 SD')",
        "    ",
        "    ax.set_xlabel('Month', fontsize=10)",
        "    ax.set_ylabel('Return (%)', fontsize=10)",
        "    ax.set_title(name, fontsize=11, fontweight='bold')",
        "    ax.legend(fontsize=9)",
        "    ax.grid(True, alpha=0.3)",
        "",
        "plt.show()",
        "",
        "# Summary table",
        "df_results = pd.DataFrame(results)",
        "print(\"\\n\" + \"=\" * 70)",
        "print(\"SUMMARY TABLE\")",
        "print(\"=\" * 70)",
        "print(df_results.to_string(index=False))",
        "",
        "print(\"\\n\ud83d\udca1 Key Insight: Higher returns come with higher risk (variability)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Key Takeaways",
        "",
        "### Measures of Dispersion",
        "",
        "| Measure | Formula | Pros | Cons | Best For |",
        "|---------|---------|------|------|----------|",
        "| **Range** | Max - Min | Simple | Only 2 values, outlier-sensitive | Quick overview |",
        "| **Variance** | $s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}$ | Uses all data | Squared units | Calculations |",
        "| **Std Dev** | $s = \\sqrt{s^2}$ | Same units as data | Outlier-sensitive | Most common |",
        "| **IQR** | Q3 - Q1 | Outlier-resistant | Uses only middle 50% | Skewed data |",
        "| **CV** | $\\frac{s}{\\bar{x}} \\times 100\\%$ | Standardized | Needs non-zero mean | Comparing datasets |",
        "",
        "### Decision Guide",
        "",
        "- **Quick overview** \u2192 Range",
        "- **Symmetric data, no outliers** \u2192 Standard Deviation  ",
        "- **Outliers or skewed** \u2192 IQR",
        "- **Compare different scales** \u2192 Coefficient of Variation",
        "- **Risk/uncertainty** \u2192 Standard Deviation or Variance",
        "",
        "### Key Insights",
        "",
        "\u2713 Variability is as important as central tendency  ",
        "\u2713 Different measures for different situations  ",
        "\u2713 Low variability = Predictable, consistent  ",
        "\u2713 High variability = Unpredictable, diverse  ",
        "",
        "### Data Science Applications",
        "",
        "- **Machine learning**: Feature scaling, variance thresholding",
        "- **Finance**: Risk assessment (volatility = std dev)",
        "- **Quality control**: Process consistency  ",
        "- **A/B testing**: Compare group variability",
        "- **Outlier detection**: IQR method",
        "",
        "---",
        "",
        "**Next Week**: Correlation and Association between Variables"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}